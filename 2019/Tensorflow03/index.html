<!DOCTYPE html>













<html class="theme-next gemini" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">




















  
  
    
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.6/jquery.fancybox.min.css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  

  
    
      
    

    
  

  
    
    
    <link rel="stylesheet" href="https://fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.0.1',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: true,
    fastclick: false,
    lazyload: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  


<link rel="stylesheet" type="text/css" href="/live2/waifu.min.css">





  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "164e692b"
    });
  daovoice('update');
  </script>


  <meta name="description" content="神经网络优化：损失函数、学习率、滑动平均、正则化">
<meta name="keywords" content="MOOC,Tensorflow,激活函数,神经网络优化,模块化">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow笔记（第三讲）">
<meta property="og:url" content="https://Smart-zhi.github.io/2019/Tensorflow03/index.html">
<meta property="og:site_name" content="小箱子">
<meta property="og:description" content="神经网络优化：损失函数、学习率、滑动平均、正则化">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower007.jpg">
<meta property="og:image" content="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower008.jpg">
<meta property="og:image" content="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower009.jpg">
<meta property="og:image" content="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower010.jpg">
<meta property="og:image" content="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower011.jpg">
<meta property="og:image" content="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower012.png">
<meta property="og:image" content="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower013.png">
<meta property="og:updated_time" content="2020-04-26T17:07:41.497Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow笔记（第三讲）">
<meta name="twitter:description" content="神经网络优化：损失函数、学习率、滑动平均、正则化">
<meta name="twitter:image" content="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower007.jpg">



  <link rel="alternate" href="/atom.xml" title="小箱子" type="application/atom+xml">




  <link rel="canonical" href="https://Smart-zhi.github.io/2019/Tensorflow03/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Tensorflow笔记（第三讲） | 小箱子</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  


  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">小箱子</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-deeplearning">

    
    
    
      
    

    

    <a href="/deeplearning/" rel="section"><i class="menu-item-icon fa fa-fw fa-circle-o"></i> <br>深度学习</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-books">

    
    
    
      
    

    

    <a href="/books/" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i> <br>图书</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-movies">

    
    
    
      
    

    

    <a href="/movies/" rel="section"><i class="menu-item-icon fa fa-fw fa-youtube-play"></i> <br>电影</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-info">

    
    
    
      
    

    

    <a href="/info/" rel="section"><i class="menu-item-icon fa fa-fw fa-address-card-o"></i> <br>个人简历</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  







  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Smart-zhi.github.io/2019/Tensorflow03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhi">
      <meta itemprop="description" content="学习笔记">
      <meta itemprop="image" content="/images/1.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小箱子">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Tensorflow笔记（第三讲）

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-11 17:14:37" itemprop="dateCreated datePublished" datetime="2019-07-11T17:14:37+08:00">2019-07-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-04-27 01:07:41" itemprop="dateModified" datetime="2020-04-27T01:07:41+08:00">2020-04-27</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Tensorflow/" itemprop="url" rel="index"><span itemprop="name">Tensorflow</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/Tensorflow03/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/Tensorflow03/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <div class="note info">
 神经网络优化：损失函数、学习率、滑动平均、正则化
</div>

<a id="more"></a>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.sigmoid()</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">f(x) = \frac{1}{1+e^{-x}}</script><p><img src="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower007.jpg" alt="tensenflower007" title="tensenflower007"></p>
<h3 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.tanh()</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">f(x)= \frac{1-e^{-2x}}{1+e^{-2x}}</script><p><img src="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower008.jpg" alt="tensenflower008" title="tensenflower008"></p>
<h3 id="Relu"><a href="#Relu" class="headerlink" title="Relu"></a>Relu</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.relu()</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\begin{aligned}
f(x) & = max(x, 0) \\
     & = \begin{cases}
          0, & \text{x$\leq$ 0}\\
          x,& \text{x > 0}
         \end{cases}
\end{aligned}</script><p><img src="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower009.jpg" alt="tensenflower009" title="tensenflower009"></p>
<h3 id="Leaky-Relu"><a href="#Leaky-Relu" class="headerlink" title="Leaky Relu"></a>Leaky Relu</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.leaky_relu(</span><br><span class="line">    features,</span><br><span class="line">    alpha=<span class="number">0.2</span>,</span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># features：一个Tensor,表示预激活值,必须是下列类型之一：float16,float32,float64,int32,int64.</span></span><br><span class="line"><span class="comment"># alpha：x &lt;0时激活函数的斜率.</span></span><br><span class="line"><span class="comment"># name：操作的名称(可选).</span></span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\begin{aligned}
f(x)  & = max(\alpha x, x) \\
      & = \begin{cases}
          \alpha x, & \text{x$\leq$ 0}\\
          x,& \text{x > 0}
         \end{cases}
\end{aligned}</script><p><img src="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower010.jpg" alt="tensenflower010" title="tensenflower010"></p>
<h3 id="NN-复杂度"><a href="#NN-复杂度" class="headerlink" title="NN 复杂度"></a>NN 复杂度</h3><p><img src="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower011.jpg" alt="tensenflower011" title="tensenflower011"></p>
<p>层数 = 2<br>总参数 = (3 * 4 + 4) + (4 * 2 + 2) = 26</p>
<h2 id="神经网络优化"><a href="#神经网络优化" class="headerlink" title="神经网络优化"></a>神经网络优化</h2><h3 id="损失函数-loss"><a href="#损失函数-loss" class="headerlink" title="损失函数(loss)"></a>损失函数(loss)</h3><p>NN 优化目标： loss最小<br>loss: MSE、 CE、 自定义</p>
<h4 id="均方误差-MSE"><a href="#均方误差-MSE" class="headerlink" title="均方误差 MSE"></a>均方误差 MSE</h4><script type="math/tex; mode=display">MSE(y_-,y)=\frac{\sum_{i=1}^{n}{(y-y_-)}^2}{n}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_mse = tf.reduce_mean(tf.square(y_-y))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>一个例子：</p>
<p>预测酸奶日销量y。x1，x2是影响日销量的因素</p>
<p>建模前，应预先采集的数据有：每日x1，x2和销量y_（即已知答案，最佳情况：产量 = 销量）</p>
<p>拟造数据集X，Y<em>，y</em> = x1+x2 </p>
<p>噪声，-0.05 ~ +0.05 拟合可以预测销量的函数</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">BATCH_SIZE = <span class="number">8</span></span><br><span class="line">SEED = <span class="number">23455</span></span><br><span class="line"></span><br><span class="line">rdm = np.random.RandomState(SEED)</span><br><span class="line">X = rdm.rand(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line">Y_ = [[x1 + x2 + (rdm.rand() / <span class="number">10.0</span> - <span class="number">0.05</span>)]  <span class="keyword">for</span> (x1,  x2) <span class="keyword">in</span> X]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入、参数、输出，定义前向传播</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape = (<span class="literal">None</span>, <span class="number">2</span>))</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape = (<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">1</span>], stddev = <span class="number">1</span>, seed = <span class="number">1</span>))</span><br><span class="line">y = tf.matmul(x, w1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数，定义后向传播</span></span><br><span class="line">loss_mse = tf.reduce_mean(tf.square(y_ - y))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.001</span>).minimize(loss_mse)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成会话，训练</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer() </span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    STEPS = <span class="number">20000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">        start = (i * BATCH_SIZE) % <span class="number">32</span></span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        sess.run(train_step, feed_dict = &#123;x: X[start: end], y_: Y_[start: end]&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">500</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"After %5d training step(s), w1 is: "</span>%(i))</span><br><span class="line">            print(sess.run(w1),<span class="string">"\n"</span>)</span><br><span class="line">    print(<span class="string">"Final w1 is: \n"</span>, sess.run(w1))</span><br><span class="line"></span><br><span class="line"><span class="comment">#  Final w1 is: </span></span><br><span class="line"><span class="comment">#   [[0.98019385]</span></span><br><span class="line"><span class="comment">#   [1.0159807 ]]</span></span><br></pre></td></tr></table></figure>
<h4 id="自定义损失函数"><a href="#自定义损失函数" class="headerlink" title="自定义损失函数"></a>自定义损失函数</h4><blockquote>
<p>如预测商品销量，预测多了，损失成本；预测少了，损失利润。</p>
<p>若利润$\neq$成本，则mse产生的loss无法利益最大化。</p>
</blockquote>
<script type="math/tex; mode=display">loss(y_-,y)=\sum_{n}{f(y_-,y)}</script><script type="math/tex; mode=display">\begin{aligned}
f(y_-,y)  & = \begin{cases}
          PROFIT \times (y_--y) , & y<y_-\\
          COST \times (y-y_-) ,& y\geq y_-
         \end{cases}
\end{aligned}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.reduce_sum(tf.where(tf.greater(y, y_), COST * (y - y_), PROFIT * (y_ - y)))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如：预测酸奶销量，酸奶成本（COST）1元，奶利润（PROFIT）9元。</p>
<p>预测少了损失利润9元，大于预测多了损失成本1元。</p>
<p>预测多了损失大，希望生成的预测函数往多了预测。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">BATCH_SIZE = <span class="number">8</span></span><br><span class="line">SEED = <span class="number">23455</span></span><br><span class="line">COST = <span class="number">1</span></span><br><span class="line">PROFIT = <span class="number">9</span></span><br><span class="line"></span><br><span class="line">rdm = np.random.RandomState(SEED)</span><br><span class="line">X = rdm.rand(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line">Y_ = [[x1 + x2 + (rdm.rand() / <span class="number">10.0</span> - <span class="number">0.05</span>)]  <span class="keyword">for</span> (x1,  x2) <span class="keyword">in</span> X]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入、参数、输出，定义前向传播</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape = (<span class="literal">None</span>, <span class="number">2</span>))</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape = (<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">1</span>], stddev = <span class="number">1</span>, seed = <span class="number">1</span>))</span><br><span class="line">y = tf.matmul(x, w1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数，定义后向传播</span></span><br><span class="line">loss = tf.reduce_sum(tf.where(tf.greater(y, y_), COST * (y - y_), PROFIT * (y_ - y)))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.001</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成会话，训练</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer() </span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    STEPS = <span class="number">20000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">        start = (i * BATCH_SIZE) % <span class="number">32</span></span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        sess.run(train_step, feed_dict = &#123;x: X[start: end], y_: Y_[start: end]&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">500</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"After %5d training step(s), w1 is: "</span>%(i))</span><br><span class="line">            print(sess.run(w1),<span class="string">"\n"</span>)</span><br><span class="line">    print(<span class="string">"Final w1 is: \n"</span>, sess.run(w1))</span><br><span class="line"></span><br><span class="line"><span class="comment">#  Final w1 is: </span></span><br><span class="line"><span class="comment">#   [[1.020171 ]</span></span><br><span class="line"><span class="comment">#   [1.0425103]]</span></span><br></pre></td></tr></table></figure>
<h4 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h4><p>表征两个概率分布之间的距离</p>
<script type="math/tex; mode=display">H(y_-,y) = - \sum y_{-}\log{y}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ce = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, <span class="number">1e-12</span>, <span class="number">1.0</span>)))</span><br><span class="line"><span class="comment"># 函数将输入log 的值做了限制，</span></span><br><span class="line"><span class="comment"># 保证：y小于1e-12时，取1e-12；y大于1.0时，取1.0</span></span><br></pre></td></tr></table></figure>
<p>当n分类的n个输出$(y_1, y_2, \cdots ,y_n)$ 通过softmax() 函数，便满足概率分布要求：</p>
<script type="math/tex; mode=display">\forall x \ P(X=x) \in [0,1] \quad \wedge \quad \sum_x{P(X=x)=1}</script><script type="math/tex; mode=display">softmax(y_i) = \frac{e^{y_i}}{\sum_{j=1}^{n}{e^{y_i}}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = y, labels = tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">cem = tf.reduce_mean(ce)</span><br></pre></td></tr></table></figure>
<h3 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h3><script type="math/tex; mode=display">w_{n+1} = w_n - learning\_rate \nabla</script><blockquote>
<p>$ w_{n+1} $ : 更新后的参数</p>
<p>$w_n$ : 当前参数</p>
<p>$learning_rate$ : 每次参数更新的幅度, 学习率大会导致振荡不收敛，学习率小导致收敛速度慢</p>
<p>$\nabla$ : 损失函数的梯度</p>
<p>$\nabla = \dfrac{\partial loss}{\partial w}$</p>
</blockquote>
<h4 id="指数衰减学习率"><a href="#指数衰减学习率" class="headerlink" title="指数衰减学习率"></a>指数衰减学习率</h4><script type="math/tex; mode=display">learning\_rate = base + decay^{\frac{global\_step}{learning\_rate\_step}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">global_step = tf.Variable(<span class="number">0</span>, trainable = <span class="literal">False</span>)</span><br><span class="line">learning_rate = tf.train.exponential_decay(</span><br><span class="line">    LEARNING_RATE_BASE,</span><br><span class="line">    global_step,</span><br><span class="line">    LEARNING_RATE_STEP,</span><br><span class="line">    LEARNING_RATE_DECAY,</span><br><span class="line">    staircase = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># LEARNING_RATE_BASE: 学习率基数</span></span><br><span class="line"><span class="comment"># LEARNING_RATE_DECAY: 学习率衰减率 (0,1)</span></span><br><span class="line"><span class="comment"># global_step: 运行 BATCH_SIZE 次数</span></span><br><span class="line"><span class="comment"># LREANING_RATE_STEP: 更新学习率需要的轮数 = 总样本数 / BATCH_SIZE</span></span><br><span class="line"><span class="comment"># staircase —— True: global_step / learning_rate_step 取整数, 学习率离散</span></span><br><span class="line"><span class="comment">#              False: 学习率连续</span></span><br></pre></td></tr></table></figure>
<p>例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义初始学习率、学习衰减率、更新学习率所需轮数</span></span><br><span class="line">LEARNING_RATE_BASE = <span class="number">0.1</span></span><br><span class="line">LEARNING_RATE_DECAY = <span class="number">0.99</span></span><br><span class="line">LEARNING_RATE_STEP = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行BATCH_SIZE 计数器，不训练</span></span><br><span class="line">global_step = tf.Variable(<span class="number">0</span>, trainable = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义指数下降学习率</span></span><br><span class="line">learning_rate = tf.train.exponential_decay(</span><br><span class="line">    LEARNING_RATE_BASE,</span><br><span class="line">    global_step,</span><br><span class="line">    LEARNING_RATE_STEP,</span><br><span class="line">    LEARNING_RATE_DECAY,</span><br><span class="line">    staircase = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义待优化参数、损失函数</span></span><br><span class="line">w = tf.Variable(tf.constant(<span class="number">5</span>, dtype = tf.float32))</span><br><span class="line">loss = tf.square(w + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义反向传播</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step = global_step)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 会话</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">40</span>):</span><br><span class="line">        sess.run(train_step)</span><br><span class="line">        learning_rate_val = sess.run(learning_rate)</span><br><span class="line">        global_step_val = sess.run(global_step)</span><br><span class="line">        w_val = sess.run(w)</span><br><span class="line">        loss_val = sess.run(loss)</span><br><span class="line">        print(<span class="string">"After %5d step(s): global_step is %3d, w is %.2f,learning rate is %.2f, loss is %.2f "</span>%(i, global_step_val, w_val, learning_rate_val, loss_val))</span><br><span class="line"></span><br><span class="line"><span class="comment">#    After     0 step(s): global_step is   1, w is 3.80,learning rate is 0.10, loss is 23.04 </span></span><br><span class="line"><span class="comment">#    After     1 step(s): global_step is   2, w is 2.85,learning rate is 0.10, loss is 14.82 </span></span><br><span class="line"><span class="comment">#    ···</span></span><br><span class="line"><span class="comment">#    After    21 step(s): global_step is  22, w is -0.92,learning rate is 0.08, loss is 0.01 </span></span><br><span class="line"><span class="comment">#    After    22 step(s): global_step is  23, w is -0.94,learning rate is 0.08, loss is 0.00 </span></span><br><span class="line"><span class="comment">#    ···</span></span><br><span class="line"><span class="comment">#    After    39 step(s): global_step is  40, w is -1.00,learning rate is 0.07, loss is 0.00</span></span><br></pre></td></tr></table></figure></p>
<h3 id="滑动平均"><a href="#滑动平均" class="headerlink" title="滑动平均"></a>滑动平均</h3><p>记录每个参数一段时间内的过往值的平均，增加了模型的泛化性。<br>针对所有的参数: w 和 b</p>
<script type="math/tex; mode=display">shadow\_variable = \beta shadow\_variable + (1- \beta)variable</script><script type="math/tex; mode=display">\beta = \min \{ init\_\beta ,\ \frac{1+num\_update}{10 + num\_update} \}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ema = tf.train.ExponentialMovingAverage(moving_average_decay, global_step)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ema_op = ema.apply([])</span></span><br><span class="line">ema_op = ema.apply(tf.trainable_variables())</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([train_step, ema_op]):</span><br><span class="line">    train_op = tf.no_op(name = <span class="string">'train'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ema.average(参数名)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># moving_average_decay 衰减率,一般比较大  init_beta</span></span><br><span class="line"><span class="comment"># global_step 当前轮数  num_update</span></span><br><span class="line"><span class="comment"># tf.trainable_variables() 所有可训练的参数</span></span><br></pre></td></tr></table></figure>
<p>例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义变量及滑动平均类</span></span><br><span class="line">w1 = tf.Variable(<span class="number">0</span>, dtype = tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义迭代次数</span></span><br><span class="line">global_step = tf.Variable(<span class="number">0</span>, trainable = <span class="literal">False</span>)</span><br><span class="line">moving_average_decay = <span class="number">0.99</span></span><br><span class="line">ema = tf.train.ExponentialMovingAverage(moving_average_decay, global_step)</span><br><span class="line">ema_op = ema.apply(tf.trainable_variables())</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印当前w1和w1的滑动平均值</span></span><br><span class="line">    print(sess.run([w1, ema.average(w1)]))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 参数w1的赋值为1</span></span><br><span class="line">    sess.run(tf.assign(w1, <span class="number">1</span>))</span><br><span class="line">    sess.run(ema_op)</span><br><span class="line">    print(sess.run([w1, ema.average(w1)]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 参数w1的赋值为10, global_step赋值为100</span></span><br><span class="line">    sess.run(tf.assign(global_step, <span class="number">100</span>))</span><br><span class="line">    sess.run(tf.assign(w1, <span class="number">10</span>))</span><br><span class="line">    sess.run(ema_op)</span><br><span class="line">    print(sess.run([w1, ema.average(w1)]))</span><br><span class="line"></span><br><span class="line">    sess.run(ema_op)</span><br><span class="line">    print(sess.run([w1, ema.average(w1)]))</span><br></pre></td></tr></table></figure>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>正则化在损失函数中引入模型复杂度指标，利用<strong>给W 加权值</strong>，弱化训练数据噪声</p>
<script type="math/tex; mode=display">loss = loss(y, y_{-}) + regularizer * loss(w)</script><h4 id="L1-正则化"><a href="#L1-正则化" class="headerlink" title="L1 正则化"></a>L1 正则化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss(w) = tf.contrib.layers.l1_regularizer(regularizer)(w)</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">loss_{L1}(w) = \sum_{i}{|w_i|}</script><h4 id="L2-正则化"><a href="#L2-正则化" class="headerlink" title="L2 正则化"></a>L2 正则化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss(w) = tf.contrib.layers.l2_regularizer(regularizer)(w)</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">loss_{L2}(w) = \sum_{i}{|w_{i}^{2}|}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.add_to_collection(<span class="string">'losser'</span>, tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br><span class="line"><span class="comment"># 把内容tf.contrib.layers.l2_regularizer(regularizer)(w)  加到集合losser对应位置，做加法</span></span><br><span class="line"></span><br><span class="line">loss = cem + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br></pre></td></tr></table></figure>
<p>例</p>
<blockquote>
<p>数据$X[x_0, x_1]$为正态分布随机点</p>
<p>当$x_0^2 + x_1^2 &lt;2$时，</p>
<p>$\ \ \ \ y_-= 1$(红色), </p>
<p>$\ \ \ \ 其余y_-=0$(蓝色)</p>
</blockquote>
<p>需要用的函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.scatter(x, y, c = color)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># plt.scatter() 散点图</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">xx, yy = np.mgrid([x_start:x_end:x_step_len, y_start:y_end:y_step_len])</span><br><span class="line">grid = np.c_[xx.ravel(), yy.ravel()]</span><br><span class="line"><span class="comment"># ravel()   拉直</span></span><br><span class="line"><span class="comment"># np.c_()   组成矩阵</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.contour(x , y, height, levels = [line_height])</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># plt.contour()   等高线图</span></span><br><span class="line"><span class="comment"># height          点(x,y)的高度</span></span><br><span class="line"><span class="comment"># line_height     等高线的高度</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">BATCH_SIZE = <span class="number">30</span></span><br><span class="line">seed = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">rdm = np.random.RandomState(seed)</span><br><span class="line">X = rdm.randn(<span class="number">300</span>, <span class="number">2</span>)</span><br><span class="line">Y_ = [int(x0 * x0 + x1 * x1 &lt; <span class="number">2</span>) <span class="keyword">for</span> (x0, x1) <span class="keyword">in</span> X]</span><br><span class="line"></span><br><span class="line">Y_c = [[<span class="string">'red'</span> <span class="keyword">if</span> y <span class="keyword">else</span> <span class="string">'blue'</span>] <span class="keyword">for</span> y <span class="keyword">in</span> Y_]</span><br><span class="line"></span><br><span class="line">X = np.vstack(X).reshape(<span class="number">-1</span>, <span class="number">2</span>)</span><br><span class="line">Y_ = np.vstack(Y_).reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(X)</span><br><span class="line">print(Y_)</span><br><span class="line">print(Y_c)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c = np.squeeze(Y_c))</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape, regularizer)</span>:</span></span><br><span class="line">    w = tf.Variable(tf.random_normal(shape), dtype = tf.float32)</span><br><span class="line">    tf.add_to_collection(<span class="string">'losses'</span>, tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span><span class="params">(shape)</span>:</span></span><br><span class="line">    b = tf.Variable(tf.constant(<span class="number">0.01</span>, shape = shape))</span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, shape = (<span class="literal">None</span>, <span class="number">2</span>))</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape = (<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">w1 = get_weight([<span class="number">2</span>, <span class="number">11</span>], <span class="number">0.01</span>)</span><br><span class="line">b1 = get_bias([<span class="number">11</span>])</span><br><span class="line">y1 = tf.nn.relu(tf.matmul(x, w1) + b1)</span><br><span class="line"></span><br><span class="line">w2 = get_weight([<span class="number">11</span>, <span class="number">1</span>], <span class="number">0.01</span>)</span><br><span class="line">b2 = get_bias([<span class="number">1</span>])</span><br><span class="line">y = tf.matmul(y1, w2) + b2</span><br><span class="line"></span><br><span class="line">loss_mse = tf.reduce_mean(tf.square(y - y_))</span><br><span class="line">loss_total = loss_mse + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反向传播，不含正则化</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">0.0001</span>).minimize(loss_mse)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    STEPS = <span class="number">40000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS): </span><br><span class="line">        start = (i * BATCH_SIZE) % <span class="number">300</span></span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        sess.run(train_step, feed_dict = &#123;x : X[start: end], y_ : Y_[start: end]&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> ==<span class="number">0</span>:</span><br><span class="line">            loss_mse_v = sess.run(loss_mse, feed_dict = &#123;x : X, y_ : Y_&#125;)</span><br><span class="line">            print(<span class="string">"After %5d step(s), loss is  %f"</span> %(i, loss_mse_v))</span><br><span class="line">    xx, yy = np.mgrid[<span class="number">-3</span>:<span class="number">3</span>:<span class="number">0.01</span>, <span class="number">-3</span>:<span class="number">3</span>:<span class="number">0.01</span>]</span><br><span class="line">    grid = np.c_[xx.ravel(), yy.ravel()]</span><br><span class="line">    probs = sess.run(y, feed_dict = &#123;x : grid&#125;)</span><br><span class="line">    probs = probs.reshape(xx.shape)</span><br><span class="line">    <span class="comment"># print("w1:\n", sess.run(w1))</span></span><br><span class="line">    <span class="comment"># print("b1:\n", sess.run(b1))</span></span><br><span class="line">    <span class="comment"># print("w2:\n", sess.run(w2))</span></span><br><span class="line">    <span class="comment"># print("b2:\n", sess.run(b2))</span></span><br><span class="line"></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c = np.squeeze(Y_c))</span><br><span class="line">plt.contour(xx, yy, probs, levels = [<span class="number">.5</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 反向传播，含正则化</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">0.0001</span>).minimize(loss_total)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    STEPS = <span class="number">40000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS): </span><br><span class="line">        start = (i * BATCH_SIZE) % <span class="number">300</span></span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        sess.run(train_step, feed_dict = &#123;x : X[start: end], y_ : Y_[start: end]&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> ==<span class="number">0</span>:</span><br><span class="line">            loss_mse_v = sess.run(loss_mse, feed_dict = &#123;x : X, y_ : Y_&#125;)</span><br><span class="line">            print(<span class="string">"After %5d step(s), loss is %f"</span> %(i, loss_mse_v))</span><br><span class="line">    xx, yy = np.mgrid[<span class="number">-3</span>:<span class="number">3</span>:<span class="number">0.01</span>, <span class="number">-3</span>:<span class="number">3</span>:<span class="number">0.01</span>]</span><br><span class="line">    grid = np.c_[xx.ravel(), yy.ravel()]</span><br><span class="line">    probs = sess.run(y, feed_dict = &#123;x : grid&#125;)</span><br><span class="line">    probs = probs.reshape(xx.shape)</span><br><span class="line">    <span class="comment"># print("w1:\n", sess.run(w1))</span></span><br><span class="line">    <span class="comment"># print("b1:\n", sess.run(b1))</span></span><br><span class="line">    <span class="comment"># print("w2:\n", sess.run(w2))</span></span><br><span class="line">    <span class="comment"># print("b2:\n", sess.run(b2))</span></span><br><span class="line"></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c = np.squeeze(Y_c))</span><br><span class="line">plt.contour(xx, yy, probs, levels = [<span class="number">.5</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower012.png" alt="tensenflower012" title="tensenflower012"></p>
<p><img src="https://gitee.com/zxz007/blogimg/raw/master/img/tensenflower013.png" alt="tensenflower013" title="tensenflower013"></p>
<h2 id="神经网络搭建方法"><a href="#神经网络搭建方法" class="headerlink" title="神经网络搭建方法"></a>神经网络搭建方法</h2><p>模块化搭建方法</p>
<h3 id="网络结构-forward-py"><a href="#网络结构-forward-py" class="headerlink" title="网络结构 forward. py"></a>网络结构 forward. py</h3><p>前向传播就是搭建网络，设计网络结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x, regularizer)</span>:</span></span><br><span class="line">    <span class="comment"># w = </span></span><br><span class="line">    <span class="comment"># b = </span></span><br><span class="line">    <span class="comment"># y = </span></span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape, regularizer)</span>:</span></span><br><span class="line">    <span class="comment"># w = tf.Variable(tf.random_normal(shape), dtype = tf.float32)</span></span><br><span class="line">    <span class="comment"># tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(regularizer)(w))</span></span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="comment"># b = tf.Variable(tf.constant(0.01, shape = shape))</span></span><br><span class="line">    <span class="keyword">return</span> b</span><br></pre></td></tr></table></figure>
<h3 id="反向传播-backward-py"><a href="#反向传播-backward-py" class="headerlink" title="反向传播 backward. py"></a>反向传播 backward. py</h3><p>方向传播就是训练网络，优化网络参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bakcward</span><span class="params">()</span>:</span></span><br><span class="line">    x = tf.placeholder()</span><br><span class="line">    y_ = tf.placeholder()</span><br><span class="line">    y = forward.forward(x, REGULARIZER)</span><br><span class="line">    global_step = tf.Variable(<span class="number">0</span>, trainable = <span class="literal">False</span>)</span><br><span class="line">    loss = </span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    loss_mse = tf.reduce_mean(tf.square(y - y_))</span><br><span class="line">    <span class="comment"># 交叉熵</span></span><br><span class="line">    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = y, labels = tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">    cem = tf.reduce_mean(cd)</span><br><span class="line">    <span class="comment"># 正则化</span></span><br><span class="line">    loss = [cem | loss_mse] + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 指数衰减学习率</span></span><br><span class="line">    <span class="comment"># LREANING_RATE_STEP = 总样本数 / BATCH_SIZE</span></span><br><span class="line">    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, LEARNING_RATE_STEP, LEARNING_RATE_DECAY, staircase = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    train_step = </span><br><span class="line">    <span class="comment"># train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)</span></span><br><span class="line">    <span class="comment"># train_step = tf.train.MomentumOptimizer(learning_rate, momentum). minimize(loss)</span></span><br><span class="line">    <span class="comment"># train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 滑动平均</span></span><br><span class="line">    ema = tf.train.ExponentialMovingAverage(moving_average_decay, global_step)</span><br><span class="line">    ema_op = ema.apply(tf.trainable_variables())</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([train_step, ema_op]):</span><br><span class="line">        train_op = tf.no_op(name = <span class="string">'train'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init_op = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init_op)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">            <span class="comment"># start = </span></span><br><span class="line">            <span class="comment"># end = </span></span><br><span class="line">            sess.run(train_step, feed_dict = &#123;x: ,y_: &#125;)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">                print()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    backward()</span><br></pre></td></tr></table></figure>
<h3 id="模块化例子"><a href="#模块化例子" class="headerlink" title="模块化例子"></a>模块化例子</h3><h4 id="generateds-py"><a href="#generateds-py" class="headerlink" title="generateds. py"></a>generateds. py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">seed = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateds</span><span class="params">()</span>:</span></span><br><span class="line">    rdm = np.random.RandomState(seed)</span><br><span class="line">    X = rdm.randn(<span class="number">300</span>, <span class="number">2</span>)</span><br><span class="line">    Y_ = [int(x0 * x0 + x1 * x1 &lt; <span class="number">2</span>)  <span class="keyword">for</span> (x0, x1) <span class="keyword">in</span> X]</span><br><span class="line">    Y_c = [[<span class="string">'red'</span> <span class="keyword">if</span> y <span class="keyword">else</span> <span class="string">'blue'</span>] <span class="keyword">for</span> y <span class="keyword">in</span> Y_]</span><br><span class="line">    X = np.vstack(X).reshape(<span class="number">-1</span>, <span class="number">2</span>)</span><br><span class="line">    Y_ = np.vstack(Y_).reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> X, Y_, Y_c</span><br></pre></td></tr></table></figure>
<h4 id="forward-py"><a href="#forward-py" class="headerlink" title="forward. py"></a>forward. py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape, regularizer)</span>:</span></span><br><span class="line">    w = tf.Variable(tf.random_normal(shape), dtype = tf.float32)</span><br><span class="line">    tf.add_to_collection(<span class="string">'losses'</span>, tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span><span class="params">(shape)</span>:</span></span><br><span class="line">    b = tf.Variable(tf.constant(<span class="number">0.01</span>, shape = shape))</span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x, regularizer)</span>:</span></span><br><span class="line">    w1 = get_weight([<span class="number">2</span>, <span class="number">11</span>], regularizer)</span><br><span class="line">    b1 = get_bias([<span class="number">11</span>])</span><br><span class="line">    y1 = tf.nn.relu(tf.matmul(x, w1) + b1)</span><br><span class="line"></span><br><span class="line">    w2 = get_weight([<span class="number">11</span>, <span class="number">1</span>], regularizer)</span><br><span class="line">    b2 = get_bias([<span class="number">1</span>])</span><br><span class="line">    y = tf.matmul(y2, w2) + b2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<h4 id="backward-py"><a href="#backward-py" class="headerlink" title="backward. py"></a>backward. py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> generateds</span><br><span class="line"><span class="keyword">import</span> forward</span><br><span class="line"></span><br><span class="line">STEPTS = <span class="number">40000</span></span><br><span class="line">BATCH_SIZE = <span class="number">30</span></span><br><span class="line">LEARNING_RATE_BASE = <span class="number">0.001</span></span><br><span class="line">LEARNING_RATE_DECAY = <span class="number">0.999</span></span><br><span class="line">REGULARIZER = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">()</span>:</span></span><br><span class="line">    x = tf.palceholder(tf.float32, shape = (<span class="literal">None</span>, <span class="number">2</span>))</span><br><span class="line">    y_ = tf.palceholder(tf.float32, shape = (<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    X, Y_, Y_c = generateds.generateds()</span><br><span class="line"></span><br><span class="line">    y = forward.forward(x, REGULARIZER)</span><br><span class="line"></span><br><span class="line">    global_step = tf.Variable(<span class="number">0</span>, trainable = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, <span class="number">300</span>/BATCH_SIZE, LEARNING_RATE_DECAY, staircase = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    loss_mse = tf.reducd_mean(tf.square(y - y_))</span><br><span class="line">    loss_total = loss_mse + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br><span class="line"></span><br><span class="line">    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss_total)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init_op = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init_op)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">            start = (i * BATCHSIZE) % <span class="number">300</span></span><br><span class="line">            end = start + BATCH_SIZE</span><br><span class="line">            sess.run(train_step, feed_dict = &#123;x: X[start: end], y_: Y_[start: end]&#125;)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">2000</span> ==<span class="number">0</span>:</span><br><span class="line">                loss_v = sess.run(loss_tatal, feed_dect = &#123;x:X, y_:Y_&#125;)</span><br><span class="line">                print(<span class="string">"After %5d step(s), loss is: %f"</span>%(i, loss_v))</span><br><span class="line">        </span><br><span class="line">        xx, yy = np.mgrid[<span class="number">-3</span>:<span class="number">3</span>:<span class="number">0.01</span>, <span class="number">-3</span>:<span class="number">3</span>:<span class="number">0.01</span>]</span><br><span class="line">        grid = np.c_[xx.ravel(), yy.ravel()]</span><br><span class="line">        probs = sess.run(y, feed_dect = &#123;x:grid&#125;)</span><br><span class="line">        probs = probs.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c = np.squeeze(Y_c))</span><br><span class="line">    plt.contour(xx, yy, probs, levels = [<span class="number">0.5</span>])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span></span><br><span class="line">    backward()</span><br></pre></td></tr></table></figure>
<hr>

      
    </div>

    



    
    
    
    
    

    

    
      
    
    
    
    
      <div class="passage_end"></div>
    

    
      <div>
        




  



<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Zhi</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    
    <a href="https://Smart-zhi.github.io/2019/Tensorflow03/" title="Tensorflow笔记（第三讲）">https://Smart-zhi.github.io/2019/Tensorflow03/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc/4.0/deed.zh" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC</a> 许可协议。转载请注明出处！</li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/MOOC/" rel="tag"> <i class="fa fa-tag"></i> MOOC</a>
          
            <a href="/tags/Tensorflow/" rel="tag"> <i class="fa fa-tag"></i> Tensorflow</a>
          
            <a href="/tags/激活函数/" rel="tag"> <i class="fa fa-tag"></i> 激活函数</a>
          
            <a href="/tags/神经网络优化/" rel="tag"> <i class="fa fa-tag"></i> 神经网络优化</a>
          
            <a href="/tags/模块化/" rel="tag"> <i class="fa fa-tag"></i> 模块化</a>
          
        </div>
      

      
      
      <div id="share-1" class=" share-component socialshar"></div>
      <script src="/js/src/social-share.min.js"></script>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/Tensorflow02/" rel="next" title="Tensorflow笔记（第二讲）">
                <i class="fa fa-chevron-left"></i> Tensorflow笔记（第二讲）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/Tensorflow04/" rel="prev" title="Tensorflow笔记（第四讲）">
                Tensorflow笔记（第四讲） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/1.jpg" alt="Zhi">
            
              <p class="site-author-name" itemprop="name">Zhi</p>
              <div class="site-description motion-element" itemprop="description">学习笔记</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">21</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/Smart-zhi" title="GitHub &rarr; https://github.com/Smart-zhi" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://gitee.com/zxz007" title="Gitee &rarr; https://gitee.com/zxz007" rel="noopener" target="_blank"><i class="fa fa-fw fa-gitlab"></i>Gitee</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:1490295322@qq.com" title="E-Mail &rarr; mailto:1490295322@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://zhidrive.herokuapp.com" title="Pan &rarr; https://zhidrive.herokuapp.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-cloud"></i>Pan</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          <div id="days" style="text-align : center; color:rgb(161, 102, 171); font-size: 14px;"></div>
<script>
function show_date_time(){
window.setTimeout("show_date_time()", 1000);
BirthDay=new Date("12/01/2018 15:00:00");
today=new Date();
timeold=(today.getTime()-BirthDay.getTime());
sectimeold=timeold/1000
secondsold=Math.floor(sectimeold);
msPerDay=24*60*60*1000
e_daysold=timeold/msPerDay
daysold=Math.floor(e_daysold);
e_hrsold=(e_daysold-daysold)*24;
hrsold=setzero(Math.floor(e_hrsold));
e_minsold=(e_hrsold-hrsold)*60;
minsold=setzero(Math.floor((e_hrsold-hrsold)*60));
seconds=setzero(Math.floor((e_minsold-minsold)*60));
document.getElementById('days').innerHTML="已运行 "+daysold+" 天 "+hrsold+" 小时 "+minsold+" 分 "+seconds+" 秒";
}
function setzero(i){
if (i<10)
{i="0" + i};
return i;
}
show_date_time();
</script>
  
<hr> 

<div id="tag-cloud" style="width:230px; height:240px;text-align:center"> 

</div>
<script src="/lib/jquery/index.js?v=2.1.3"></script>
<script src="/js/src/jquery.svg3dtagcloud.min.js"></script>
<div style="display:none" type="text">
<a class="tag-link" href="/tags/HashMap/">HashMap</a><a class="tag-link" href="/tags/Java/">Java</a><a class="tag-link" href="/tags/Linux-学习/">Linux 学习</a><a class="tag-link" href="/tags/MNIST/">MNIST</a><a class="tag-link" href="/tags/MOOC/">MOOC</a><a class="tag-link" href="/tags/MySQL/">MySQL</a><a class="tag-link" href="/tags/Tensorflow/">Tensorflow</a><a class="tag-link" href="/tags/hexo/">hexo</a><a class="tag-link" href="/tags/jdk8/">jdk8</a><a class="tag-link" href="/tags/markdown/">markdown</a><a class="tag-link" href="/tags/全连接网络/">全连接网络</a><a class="tag-link" href="/tags/关系数据库/">关系数据库</a><a class="tag-link" href="/tags/卷积/">卷积</a><a class="tag-link" href="/tags/图像/">图像</a><a class="tag-link" href="/tags/数据库/">数据库</a><a class="tag-link" href="/tags/文本文件处理/">文本文件处理</a><a class="tag-link" href="/tags/模块化/">模块化</a><a class="tag-link" href="/tags/激活函数/">激活函数</a><a class="tag-link" href="/tags/神经网络优化/">神经网络优化</a><a class="tag-link" href="/tags/范式/">范式</a><a class="tag-link" href="/tags/边缘检测/">边缘检测</a></div>
<script type="text/javascript" charset="utf-8" src="/js/src/mytag_siber.js"></script>

 
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#激活函数"><span class="nav-number">1.</span> <span class="nav-text">激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid"><span class="nav-number">1.1.</span> <span class="nav-text">Sigmoid</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tanh"><span class="nav-number">1.2.</span> <span class="nav-text">tanh</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Relu"><span class="nav-number">1.3.</span> <span class="nav-text">Relu</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Leaky-Relu"><span class="nav-number">1.4.</span> <span class="nav-text">Leaky Relu</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NN-复杂度"><span class="nav-number">1.5.</span> <span class="nav-text">NN 复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#神经网络优化"><span class="nav-number">2.</span> <span class="nav-text">神经网络优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数-loss"><span class="nav-number">2.1.</span> <span class="nav-text">损失函数(loss)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#均方误差-MSE"><span class="nav-number">2.1.1.</span> <span class="nav-text">均方误差 MSE</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义损失函数"><span class="nav-number">2.1.2.</span> <span class="nav-text">自定义损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#交叉熵"><span class="nav-number">2.1.3.</span> <span class="nav-text">交叉熵</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习率"><span class="nav-number">2.2.</span> <span class="nav-text">学习率</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#指数衰减学习率"><span class="nav-number">2.2.1.</span> <span class="nav-text">指数衰减学习率</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#滑动平均"><span class="nav-number">2.3.</span> <span class="nav-text">滑动平均</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化"><span class="nav-number">2.4.</span> <span class="nav-text">正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#L1-正则化"><span class="nav-number">2.4.1.</span> <span class="nav-text">L1 正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#L2-正则化"><span class="nav-number">2.4.2.</span> <span class="nav-text">L2 正则化</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#神经网络搭建方法"><span class="nav-number">3.</span> <span class="nav-text">神经网络搭建方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#网络结构-forward-py"><span class="nav-number">3.1.</span> <span class="nav-text">网络结构 forward. py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#反向传播-backward-py"><span class="nav-number">3.2.</span> <span class="nav-text">反向传播 backward. py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模块化例子"><span class="nav-number">3.3.</span> <span class="nav-text">模块化例子</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#generateds-py"><span class="nav-number">3.3.1.</span> <span class="nav-text">generateds. py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#forward-py"><span class="nav-number">3.3.2.</span> <span class="nav-text">forward. py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#backward-py"><span class="nav-number">3.3.3.</span> <span class="nav-text">backward. py</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhi</span>

  

  
</div>



<div class="powered-by">
<a href="https://www.upyun.com" target="_blank" rel="noopener"><img src="https://nobige.coding.net/p/static/d/static/git/raw/master/upyun/logo5.png" width="60" style="display: inline;" alt="upyun"></a>
</div>
<hr>
<div class="powered-by">
<a href="https://www.beian.miit.gov.cn" target="_blank" rel="noopener">
晋ICP备20004223号
</a>
</div>







        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>







  






  















  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.1"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.1"></script>




  
  <script src="/js/src/scrollspy.js?v=7.0.1"></script>
<script src="/js/src/post-details.js?v=7.0.1"></script>



  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  

  

  

  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'Ez24jGLqE6WDJGQ76uMiFqWk-gzGzoHsz',
    appKey: 'PYdwpf5qkk87AWTSWoDmw18O',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn'
  });
</script>




  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>
  <!-- 打字礼花及震动特效 -->
  <script type="text/javascript" src="/js/src/activate-power-mode.js"></script>
  <script>
    POWERMODE.colorful = true; // ture 为启用礼花特效
    POWERMODE.shake = false; // false 为禁用震动特效
    document.body.addEventListener('input', POWERMODE);
  </script> 





  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  
<script>
  $('.highlight').each(function(i, e) {
    var $wrap = $('<div>').addClass('highlight-wrap');
    $(e).after($wrap);
    $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function(e) {
      var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
        return $(e).text();
      }).toArray().join('\n');
      var ta = document.createElement('textarea');
      var yPosition = window.pageYOffset || document.documentElement.scrollTop;
      ta.style.top = yPosition + 'px'; // Prevent page scroll
      ta.style.position = 'absolute';
      ta.style.opacity = '0';
      ta.readOnly = true;
      ta.value = code;
      document.body.appendChild(ta);
      ta.select();
      ta.setSelectionRange(0, code.length);
      ta.readOnly = false;
      var result = document.execCommand('copy');
      
        if (result) $(this).text('复制成功');
        else $(this).text('复制失败');
      
      ta.blur(); // For iOS
      $(this).blur();
    })).on('mouseleave', function(e) {
      var $b = $(this).find('.copy-btn');
      setTimeout(function() {
        $b.text('复制');
      }, 300);
    }).append(e);
  })
</script>


  

  

  <!-- 页面点击小红心/ 文字 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script> 


</body></html>